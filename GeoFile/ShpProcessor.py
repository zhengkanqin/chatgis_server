# backend/ShpProcessor.py

from connection_manager import manager
from autogen_core.tools import FunctionTool
from pyproj.exceptions import CRSError
from pyogrio.errors import DataSourceError
import geopandas as gpd
import os
import json
import logging
import shutil
import tempfile
import numpy as np
from typing import Annotated
from pydantic import Field
from datetime import datetime


def classify_field_type(dtype, data):
    """è¯¦ç»†å­—æ®µç±»åž‹åˆ†ç±»åˆ¤æ–­"""
    if np.issubdtype(dtype, np.floating):
        if dtype == np.float32:
            return "Float"
        return "Double"
    elif np.issubdtype(dtype, np.integer):
        min_val = data.min()
        max_val = data.max()
        if -32768 <= min_val and max_val <= 32767:
            return "Short Integer"
        return "Long Integer"
    elif np.issubdtype(dtype, np.datetime64) or isinstance(data.iloc[0], datetime):
        return "Date"
    elif dtype == object:
        sample = data.dropna().iloc[0] if not data.empty else ""
        if isinstance(sample, str) and len(sample.encode('utf-8')) < 254:
            return "Text"
        return "BLOB"  # å®žé™…shapefileä¸æ”¯æŒï¼Œä¿ç•™è¯†åˆ«èƒ½åŠ›
    return "Unknown"


async def read_shp_file(file_path: str):
    """
    è¯»å–å¹¶è§£æžåœ°ç†æ•°æ®æ–‡ä»¶ï¼Œæå–å…³é”®åœ°ç†ä¿¡æ¯ç‰¹å¾

    å‚æ•°:
    - file_path: éœ€è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„

    è¿”å›ž:
    - å¤„ç†ç»“æžœçŠ¶æ€åŠå…³é”®ç‰¹å¾æ‘˜è¦
    """
    try:
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if not os.path.exists(file_path):
            err_msg = f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
            await manager.send_message(err_msg)
            return {"status": "error", "message": err_msg}

        # è¯»å–shpæ–‡ä»¶
        try:
            gdf = gpd.read_file(file_path)
        except CRSError as crs_err:
            # å°è¯•è‡ªåŠ¨ä¿®å¤æ— æ•ˆçš„EPSGä»£ç 
            try:
                gdf = await handle_crs_error(file_path, crs_err, manager)
            except Exception as read_error:
                # ç”Ÿæˆè¯¦ç»†é”™è¯¯æŠ¥å‘Š
                error_info = {
                    "åŽŸå› ": "åæ ‡ç³»ä¿®å¤å¤±è´¥",
                    "æŠ€æœ¯è¯Šæ–­": [
                        f"åˆæ¬¡é”™è¯¯: {str(crs_err)}",
                        f"ç§»é™¤PRJåŽé”™è¯¯: {str(read_error)}",
                        "å¯èƒ½åŽŸå› :",
                        "1. æ•°æ®æœ¬èº«åæ ‡å€¼å¼‚å¸¸",
                        "2. å‡ ä½•æ•°æ®æŸå",
                        "3. éœ€è¦æ‰‹åŠ¨æŒ‡å®šåæ ‡ç³»"
                    ],
                    "ä¿®å¤å»ºè®®": [
                        "ç»ˆæžæ–¹æ¡ˆï¼šå¼ºåˆ¶æŒ‡å®šåæ ‡ç³»å‚æ•°",
                        "æ“ä½œæ­¥éª¤ï¼š",
                        "1. ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æŸ¥çœ‹åæ ‡å€¼èŒƒå›´",
                        "2. æ ¹æ®æ•°æ®æ¥æºæŽ¨æµ‹æ­£ç¡®åæ ‡ç³»",
                        "3. ä½¿ç”¨QGISé‡æ–°å®šä¹‰æŠ•å½±"
                    ]
                }

                err_msg = format_crs_error(file_path, error_info)
                await manager.send_message(err_msg)
                logging.error(f"CRS Repair Failed: {str(read_error)}")
                return {"status": "error", "message": err_msg}

        except DataSourceError as data_err:
            return await handle_datasource_error(file_path, data_err, manager)

        except FileNotFoundError as e:
            error_info = {
                "åŽŸå› ": "æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨æˆ–å·²è¢«ç§»åŠ¨",
                "å»ºè®®": [
                    "1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦æˆ–ç‰¹æ®Šå­—ç¬¦",
                    "2. ç¡®è®¤æ–‡ä»¶åŽç¼€åä¸Žå®žé™…æ ¼å¼ä¸€è‡´ï¼ˆå¦‚.shp/.geojsonï¼‰",
                    "3. å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„ä»£æ›¿ç›¸å¯¹è·¯å¾„"
                ]
            }
            err_msg = f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}\n{format_error(error_info)}"

        except PermissionError as e:
            error_info = {
                "åŽŸå› ": "æ–‡ä»¶è®¿é—®æƒé™ä¸è¶³",
                "å»ºè®®": [
                    "1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨ï¼ˆå¦‚Excelã€GISè½¯ä»¶ï¼‰",
                    "2. å³é”®æ–‡ä»¶å±žæ€§â†’å®‰å…¨â†’æ·»åŠ ç”¨æˆ·è¯»å†™æƒé™",
                    "3. å°è¯•å°†æ–‡ä»¶å¤åˆ¶åˆ°æœ‰å†™å…¥æƒé™çš„ç›®å½•"
                ]
            }
            err_msg = f"æƒé™é”™è¯¯ï¼š{str(e)}\n{format_error(error_info)}"

        except UnicodeDecodeError as e:
            error_info = {
                "åŽŸå› ": "æ–‡ä»¶ç¼–ç ä¸å…¼å®¹",
                "å»ºè®®": [
                    "1. å°è¯•æŒ‡å®šç¼–ç å‚æ•°ï¼šgpd.read_file(file_path, encoding='gbk')",
                    "2. ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨çš„ç¼–ç æ ¼å¼",
                    "3. å°†æ–‡ä»¶å¦å­˜ä¸ºUTF-8ç¼–ç æ ¼å¼"
                ]
            }
            err_msg = f"ç¼–ç é”™è¯¯ï¼š{str(e)}\n{format_error(error_info)}"

        except Exception as e:
            error_info = {
                "åŽŸå› ": "æœªçŸ¥æ•°æ®è§£æžé”™è¯¯",
                "å»ºè®®": [
                    "1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆç‰¹åˆ«å…³æ³¨ZIPåŽ‹ç¼©åŒ…ï¼‰",
                    "2. å°è¯•ç”¨gpd.read_file(file_path, driver='GeoJSON')æŒ‡å®šé©±åŠ¨",
                    "3. æä¾›æ–‡ä»¶æ ·æœ¬ç»™æŠ€æœ¯äººå‘˜åˆ†æž"
                ]
            }
            err_msg = f"æ•°æ®è§£æžå¤±è´¥ï¼š{str(e)}\n{format_error(error_info)}"

        # è®¡ç®—åæ ‡èŒƒå›´
        bounds = gdf.total_bounds
        coord_range = {
            "min_lon": bounds[0],
            "max_lon": bounds[2],
            "min_lat": bounds[1],
            "max_lat": bounds[3]
        }

        # æž„å»ºç‰¹å¾æ‘˜è¦
        summary = {
            "file_info": {
                "file_name": os.path.basename(file_path),
                "crs": str(gdf.crs),
                "geometry_type": gdf.geometry.type.unique().tolist(),
                "total_features": len(gdf),
                "coord_range": coord_range
            },
            "attributes": {
                "fields": {},
                "special_fields": {
                    "Geometry": [],
                    "GUID": [],
                    "ObjectID": []
                }
            }
        }

        # åˆ†æžæ¯ä¸ªå­—æ®µ
        for col in gdf.columns:
            if col == 'geometry':
                summary['attributes']['special_fields']['Geometry'].append({
                    "type": "Geometry",
                    "count": len(gdf)
                })
                continue

            field_type = classify_field_type(gdf[col].dtype, gdf[col])
            stats = {}

            # æ•°å€¼åž‹å¤„ç†
            if field_type in ["Float", "Double", "Short Integer", "Long Integer"]:
                stats = {
                    "type": field_type,
                    "min": gdf[col].min(),
                    "max": gdf[col].max(),
                    "mean": gdf[col].mean()
                }
            # æ–‡æœ¬åž‹å¤„ç†
            elif field_type == "Text":
                unique_values = gdf[col].dropna().unique()
                stats = {
                    "type": "Text",
                    "unique_count": len(unique_values),
                    "sample_values": unique_values.tolist()[:5] if len(unique_values) <= 5 else None
                }
            # æ—¥æœŸåž‹å¤„ç†
            elif field_type == "Date":
                stats = {
                    "type": "Date",
                    "min": gdf[col].min().strftime("%Y-%m-%d"),
                    "max": gdf[col].max().strftime("%Y-%m-%d")
                }
            # ç‰¹æ®Šå­—æ®µå¤„ç†
            elif col.lower() in ['fid', 'objectid']:
                summary['attributes']['special_fields']['ObjectID'].append({
                    "type": "Long Integer",
                    "count": len(gdf[col].unique())
                })
                continue

            summary['attributes']['fields'][col] = stats

        # æ ¼å¼åŒ–è¾“å‡ºæ¶ˆæ¯
        output = [
            f"- åœ°ç†æ•°æ®å¤„ç†å®Œæˆï¼š{summary['file_info']['file_name']}",
            "  - æ•°æ®æ¦‚å†µï¼š",
            f"    - æ–‡ä»¶ç±»åž‹ï¼šSHP",
            f"    - åæ ‡ç³»ï¼š{summary['file_info']['crs']}",
            f"    - å‡ ä½•ç±»åž‹ï¼š{', '.join(summary['file_info']['geometry_type'])}",
            f"    - è¦ç´ æ€»æ•°ï¼š{summary['file_info']['total_features']}",
            "  - åæ ‡èŒƒå›´ï¼š",
            f"    - ç»åº¦ï¼š{summary['file_info']['coord_range']['min_lon']:.4f} ~ {summary['file_info']['coord_range']['max_lon']:.4f}",
            f"    - çº¬åº¦ï¼š{summary['file_info']['coord_range']['min_lat']:.4f} ~ {summary['file_info']['coord_range']['max_lat']:.4f}",
            "  - å±žæ€§å­—æ®µï¼š"
        ]

        # æ·»åŠ å­—æ®µè¯¦ç»†ä¿¡æ¯
        for col, stats in summary['attributes']['fields'].items():
            if stats['type'] in ["Float", "Double", "Short Integer", "Long Integer"]:
                output.append(
                    f"    - æ•°å€¼å­—æ®µ [{col}]ï¼ˆ{stats['type']}ï¼‰ï¼š"
                    f"å¹³å‡ {stats['mean']:.2f} | æœ€å¤§ {stats['max']} | æœ€å° {stats['min']}"
                )
            elif stats['type'] == "Text":
                if stats['unique_count'] <= 5:
                    values = ', '.join(map(str, stats['sample_values']))
                    output.append(f"    - æ–‡æœ¬å­—æ®µ [{col}]ï¼šåŒ…å«å€¼ {values}")
                else:
                    output.append(f"    - æ–‡æœ¬å­—æ®µ [{col}]ï¼šå”¯ä¸€å€¼æ•°é‡ {stats['unique_count']}")
            elif stats['type'] == "Date":
                output.append(
                    f"    - æ—¥æœŸå­—æ®µ [{col}]ï¼šèŒƒå›´ {stats['min']} è‡³ {stats['max']}"
                )

        # æ·»åŠ ç‰¹æ®Šå­—æ®µ
        for field_type, entries in summary['attributes']['special_fields'].items():
            for entry in entries:
                output.append(
                    f"    - ç³»ç»Ÿå­—æ®µ [{field_type}]ï¼š{entry['type']}ç±»åž‹ï¼Œå…±{entry['count']}æ¡è®°å½•"
                )

        # å‘é€å¤„ç†ç»“æžœ
        result_msg = "\n".join(output)
        await manager.send_message(result_msg)

        # è®°å½•åŽŸå§‹æ•°æ®
        logging.info(f"SHPå¤„ç†åŽŸå§‹æ•°æ®ï¼š{json.dumps(summary, indent=2)}")

        return {"status": "success", "data": result_msg}

    except Exception as e:
        error_msg = f"å¤„ç†shpæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        await manager.send_message(error_msg)
        logging.error(error_msg, exc_info=True)
        return {"status": "error", "message": error_msg}


async def handle_crs_error(file_path, error, manager):
    """ä¸“é—¨å¤„ç†åæ ‡ç³»é”™è¯¯"""
    error_info = {
        "åŽŸå› ": "åæ ‡ç³»å®šä¹‰å¼‚å¸¸",
        "å…·ä½“è¯Šæ–­": [
            f"åŽŸå§‹é”™è¯¯: {str(error)}",
            "å¯èƒ½åŽŸå› :",
            "1. PRJæ–‡ä»¶ç¼ºå¤±æˆ–æŸå",
            "2. ä½¿ç”¨äº†éžæ ‡å‡†EPSGä»£ç ",
            "3. æ•°æ®å¯¼å‡ºæ—¶æœªæ­£ç¡®è®¾ç½®æŠ•å½±"
        ],
        "ä¿®å¤å»ºè®®": [
            "æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨QGISä¿®å¤åæ ‡ç³»",
            "   1. åœ¨QGISä¸­å³é”®å›¾å±‚ â†’ è®¾ç½®åæ ‡ç³»",
            "   2. å¯¼å‡ºä¸ºæ–°çš„shapefile",
            "æ–¹æ¡ˆäºŒï¼šæ‰‹åŠ¨ä¿®å¤PRJæ–‡ä»¶",
            "   ç”¨æ–‡æœ¬ç¼–è¾‘å™¨åˆ›å»ºåŒåçš„.prjæ–‡ä»¶",
            "   æ’å…¥æ ‡å‡†WKTåæ ‡ç³»å®šä¹‰"
        ]
    }

    # ç”Ÿæˆè¯¦ç»†é”™è¯¯æŠ¥å‘Š
    err_msg = (
        f"ðŸš¨ åæ ‡ç³»é…ç½®é”™è¯¯: {os.path.basename(file_path)}\n"
        f"â–Œ{format_error(error_info)}\n"
        "ðŸ’¡ æ­£åœ¨å°è¯•è‡ªåŠ¨ä¿®å¤â€¦â€¦"
    )

    await manager.send_message(err_msg)
    logging.error(f"CRS Error: {str(error)}")

    """å¤„ç†åæ ‡ç³»é”™è¯¯å¹¶å°è¯•è‡ªåŠ¨ä¿®å¤.prjæ–‡ä»¶é—®é¢˜"""
    prj_path = os.path.splitext(file_path)[0] + ".prj"
    temp_prj = None
    prj_removed = False

    # å°è¯•å¤‡ä»½å¹¶ç§»é™¤.prjæ–‡ä»¶
    if os.path.exists(prj_path):
        temp_prj = tempfile.NamedTemporaryFile(delete=False, suffix=".prj")
        shutil.move(prj_path, temp_prj.name)
        prj_removed = True
        logging.info(f"å·²ä¸´æ—¶ç§»é™¤PRJæ–‡ä»¶: {prj_path} â†’ {temp_prj.name}")

    # å°è¯•é‡æ–°è¯»å–æ•°æ®ï¼ˆæ— .prjæ–‡ä»¶çŠ¶æ€ï¼‰
    gdf = gpd.read_file(file_path)

    await manager.send_message(
        f"æˆåŠŸè¯»å–æ–‡ä»¶ {os.path.basename(file_path)}\n"
        f"- ç§»é™¤æ— æ•ˆPRJæ–‡ä»¶åŽåæ ‡ç³»: {gdf.crs}"
    )

    return gdf


async def handle_datasource_error(file_path, error, manager):
    """å¤„ç†æ•°æ®æºé”™è¯¯"""
    error_info = {
        "åŽŸå› ": "æ•°æ®æºè¯»å–å¤±è´¥",
        "å…·ä½“è¯Šæ–­": analyze_datasource_error(error),
        "ä¿®å¤å»ºè®®": [
            "æ­¥éª¤1ï¼šæ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§ï¼ˆå¿…é¡»åŒ…å«.shp/.shx/.dbfç­‰ï¼‰",
            "æ­¥éª¤2ï¼šéªŒè¯æ–‡ä»¶ç¼–ç ï¼šä½¿ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æŸ¥çœ‹æ˜¯å¦æœ‰ä¹±ç ",
            "æ­¥éª¤3ï¼šå°è¯•æŒ‡å®šé©±åŠ¨å‚æ•°ï¼šgpd.read_file(file_path, driver='ESRI Shapefile')",
            "æ­¥éª¤4ï¼šä½¿ç”¨QGISæ‰“å¼€æ–‡ä»¶éªŒè¯æ•°æ®æœ‰æ•ˆæ€§"
        ]
    }

    err_msg = (
        f"ðŸ”§ æ•°æ®æºé”™è¯¯: {os.path.basename(file_path)}\n"
        f"â–Œ{format_error(error_info)}\n"
        "ðŸ’¡ å¯å°è¯•ä¿®å¤å‘½ä»¤ï¼š/fix_datasource"
    )

    await manager.send_message(err_msg)
    logging.error(f"DataSource Error: {str(error)}")
    return {"status": "error", "message": err_msg}


def analyze_datasource_error(error):
    """æ™ºèƒ½åˆ†æžæ•°æ®æºé”™è¯¯åŽŸå› """
    error_msg = str(error).lower()
    reasons = []

    if "no such file" in error_msg:
        reasons.append("æ–‡ä»¶è·¯å¾„åŒ…å«ä¸­æ–‡å­—ç¬¦æˆ–ç‰¹æ®Šç¬¦å·")
    elif "unrecognized data source" in error_msg:
        reasons.append("æ–‡ä»¶æ‰©å±•åä¸Žå®žé™…æ ¼å¼ä¸åŒ¹é…")
    elif "failed to open" in error_msg:
        reasons.extend(["æ–‡ä»¶æ­£åœ¨è¢«å…¶ä»–ç¨‹åºå ç”¨", "æ–‡ä»¶æƒé™ä¸è¶³"])
    elif ".shx" in error_msg:
        reasons.append("Shapefileç»„ä»¶ä¸å®Œæ•´ï¼ˆç¼ºå°‘.shxæ–‡ä»¶ï¼‰")

    return reasons or ["æœªçŸ¥æ•°æ®æºé”™è¯¯ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯Šæ–­"]


def format_error(error_info):
    """å¢žå¼ºçš„é”™è¯¯æ ¼å¼åŒ–"""
    sections = [f"â–  é”™è¯¯åŽŸå› \n{error_info['åŽŸå› ']}", "â–¼ æŠ€æœ¯è¯Šæ–­\n" + "\n".join(error_info["å…·ä½“è¯Šæ–­"]),
                "âš™ ä¿®å¤æ–¹æ¡ˆ\n" + "\n".join(error_info["ä¿®å¤å»ºè®®"])]
    return "\n\n".join(sections)


def format_crs_error(file_path, error_info):
    """æ ¼å¼åŒ–åæ ‡ç³»é”™è¯¯ä¿¡æ¯"""
    return (
        f"ðŸš¨ åæ ‡ç³»ä¿®å¤å¤±è´¥: {os.path.basename(file_path)}\n"
        f"â–  é”™è¯¯åŽŸå› \n{error_info['åŽŸå› ']}\n\n"
        f"â–¼ æŠ€æœ¯è¯Šæ–­\n" + "\n".join(error_info["æŠ€æœ¯è¯Šæ–­"]) + "\n\n"
        f"âš™ ä¿®å¤å»ºè®®\n" + "\n".join(error_info["ä¿®å¤å»ºè®®"])
    )


read_tool = FunctionTool(
    read_shp_file,
    name="read_shapefile",
    description="è¯»å–å¹¶è§£æžshapefileåœ°ç†æ•°æ®æ–‡ä»¶ï¼Œæå–åæ ‡ç³»ã€å‡ ä½•ç±»åž‹ã€å±žæ€§å­—æ®µç»Ÿè®¡ç­‰å…³é”®ç‰¹å¾ä¿¡æ¯ï¼Œå¹¶å°†åˆ†æžç»“æžœå‘é€è‡³å‰ç«¯å±•ç¤º",
)
